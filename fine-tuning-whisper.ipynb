{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a407244-d875-42b5-b75d-d50ba07da345",
   "metadata": {},
   "source": [
    "# [wip] Fine-tuning Whisper on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795b502-2e2b-462b-a640-1a600c8aed1c",
   "metadata": {},
   "source": [
    "In this notebook, we create a SageMaker Pipeline to fine-tune Whisper algorithm for a specific language. Whisper is a pre-trained Automatic Speech Recognition (ASR) [[paper](https://cdn.openai.com/papers/whisper.pdf)]. \n",
    "\n",
    "This notebook can be run using Data Science 3.0 with ml.t3.medium.\n",
    "We use [CommonVoice](https://huggingface.co/datasets/mozilla-foundation/common_voice_13_0) dataset to fine-tune Whisper model.\n",
    "\n",
    "TODO:\n",
    "  - Consider running on [fleurs dataset](https://huggingface.co/datasets/google/fleurs/viewer/id_id/train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075d68a9-a690-4a47-a1db-eae044eb33a0",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "  - Hugging Face hub account to get access token to download the datasets. You need to create Hungging Face account and follow this guide to create an access token: https://huggingface.co/docs/hub/security-tokens\n",
    "  - Following best practice, we store the Hugging Face Hub access token in AWS Secrets Manager. See the screenshots below to store access token to AWS Secret Manager. You also need to allow Amazon SageMaker to read AWS Secrets Manager.\n",
    "  \n",
    "![Secret Type](img/secret_manager1.png \"Secret Type\")\n",
    "\n",
    "![Secret Name](img/secret_manager2.png \"Secret Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad451a7-5d96-4327-9ddc-9954f21a7aba",
   "metadata": {},
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c3cb6-18bd-49e2-bc1c-8e278cf759eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b180f701-429c-4f01-bf3e-42e50f3caf92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "from datetime import datetime\n",
    "from sagemaker.huggingface import HuggingFaceProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.steps import ProcessingStep, CacheConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c78b79-d373-40dd-9e2c-7b554cb1ee04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ffbbe9-471a-4caf-91d3-328b7e90a7d0",
   "metadata": {},
   "source": [
    "## Application Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0feb37-e299-4382-945a-a8661595d2da",
   "metadata": {},
   "source": [
    "Let's define several input parameters for our Whisper fine-tuning pipeline.\n",
    "\n",
    "  - `DATASET` refers to dataset name. In this case, we are using Common Voice dataset (`common-voice`). TODO: Try `fleurs` dataset.\n",
    "  - `HFHUB_SECRET` refers to the name of AWS Secrets that contain your Hugging Face access token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7373a-3804-4022-8c17-e6c599ad1c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET = \"common-voice\"\n",
    "HFHUB_SECRET= \"hfhub\"\n",
    "\n",
    "LANGUAGE_NAMES = {\n",
    "    \"id\": \"indonesian\",\n",
    "    \"vi\": \"vietnamese\",\n",
    "    \"ta\": \"tamil\",\n",
    "    \"th\": \"thai\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec66582-cb79-4394-9959-22a0b01ea656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_data_s3uri_prefix = f\"s3://{bucket}/whisper-data/{DATASET}-\"\n",
    "pipeline_name = \"whisper-fine-tuning\"  # SageMaker Pipeline name\n",
    "\n",
    "print(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da6b81-7bbf-49f8-a33c-06fd83ac5b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "\n",
    "language_code = ParameterString(name=\"LanguageCode\")\n",
    "language_name = ParameterString(name=\"LanguageName\")\n",
    "\n",
    "# AWS Secrets Manager Secret containing your Hugging Face Hub access token:\n",
    "hf_secret = ParameterString(name=\"HFSecretName\")\n",
    "\n",
    "# processing step parameters\n",
    "fetching_instance_type = ParameterString(name=\"FetchingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "\n",
    "# training step parameters\n",
    "# training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.g5.2xlarge\")\n",
    "training_max_steps = ParameterString(name=\"TrainingMaxSteps\", default_value=\"200\")\n",
    "\n",
    "# evaluation step parameters\n",
    "evaluation_instance_type = ParameterString(name=\"EvaluationInstanceType\", default_value=\"ml.g4dn.xlarge\")\n",
    "\n",
    "# name of model package in the model registry\n",
    "model_package_name = ParameterString(name=\"ModelPackageName\", default_value=\"fine-tuned-whisper\")\n",
    "\n",
    "# model performance step parameters\n",
    "wer_threshold = ParameterFloat(name=\"WERThreshold\", default_value=35.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8034f0-c19d-4192-9c56-a2814844cf41",
   "metadata": {},
   "source": [
    "## Pre-processing Step: Fetching Dataset from CommonVoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae7d59-c39a-46ef-a028-93ecf39dcc06",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Need to specify explicit image_uri otherwise HuggingFaceProcessor complains about not having a\n",
    "# non-GPU image when used with m*/c*/etc non-accelerated instance types:\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    \"huggingface\",\n",
    "    region=os.environ[\"AWS_REGION\"],\n",
    "    version=\"4.28\",\n",
    "    base_framework_version=\"pytorch2.0\",\n",
    "    py_version=\"py310\",\n",
    "    image_scope=\"training\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a00f6-53b7-40f5-abd7-8872198c8c98",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "#Initialize the HuggingFaceProcessor\n",
    "fetch_processor = HuggingFaceProcessor(\n",
    "    sagemaker_session=pipeline_session,\n",
    "    base_job_name=f\"whisper-fetch-dataset\",\n",
    "    role=role, \n",
    "    image_uri=image_uri,\n",
    "    instance_count=1,\n",
    "    instance_type=fetching_instance_type,  #\"ml.g4dn.xlarge\", \"ml.m5.2xlarge\"\n",
    "    py_version=\"py310\",\n",
    "    pytorch_version=\"2.0\", \n",
    "    transformers_version=\"4.28\", \n",
    "    volume_size_in_gb=40,\n",
    ")\n",
    "\n",
    "fetch_processor_args = fetch_processor.run(\n",
    "    code=\"entry_fetch.py\",\n",
    "    source_dir=\"src\",\n",
    "    inputs=None,\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"output\",\n",
    "            source=\"/opt/ml/processing/output\",\n",
    "            destination=Join(on=\"\", \n",
    "                             values=[\n",
    "                                 source_data_s3uri_prefix,\n",
    "                                 language_code\n",
    "                             ]),\n",
    "            s3_upload_mode=\"Continuous\",\n",
    "        )    \n",
    "    ],\n",
    "    arguments=[\n",
    "        # Name/ARN of your AWS Secrets Manager Secret containing your Hugging Face Hub access token:\n",
    "        \"--hf_secret_id\", hf_secret,\n",
    "        \"--language_code\", language_code,\n",
    "        # Normalize audio sample rate at pre-processing time to save time in training job:\n",
    "        \"--norm_sample_rate\", \"16000\",\n",
    "        # More shards to help scale later pre-processing in the training job:\n",
    "        \"--save_num_shards\", \"48\",\n",
    "    ],\n",
    "    wait=True,\n",
    "    logs=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91240bf5-de1b-4e47-87e9-db46ca5d3a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_fetch = ProcessingStep(\n",
    "    name=\"fetch_data\",\n",
    "    step_args=fetch_processor_args,\n",
    "    cache_config=CacheConfig(enable_caching=True, expire_after=\"PT24H\"),  # Caching step for 24 hours\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60272c0-4d86-4bb6-850b-f63b8215e9e8",
   "metadata": {},
   "source": [
    "## Training Step: Fine-tuning Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd2e45-a1d3-48e7-8d22-163a5b9ce4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace as HuggingFaceEstimator\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "from src.sagemaker_whisper import notebook as util\n",
    "\n",
    "# configuration for running training on smdistributed data parallel\n",
    "#distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "\n",
    "hyperparameters = {\n",
    "    \"model_name_or_path\": \"openai/whisper-small\", #\"openai/whisper-medium\", # Not whisper-large-v2 yet: CUDA OOM\n",
    "    \"language\": language_name,\n",
    "    \"per_device_train_batch_size\": 32, #8, #16, #32,\n",
    "    \"per_device_eval_batch_size\": 16, #8, #16,\n",
    "    \"gradient_accumulation_steps\": 1, #4, #2, #1,\n",
    "    \"gradient_checkpointing\": \"true\",  # Not needed if not VRAM-constrained?\n",
    "    \"fp16\": True,\n",
    "    \"fp16_full_eval\": True,\n",
    "    \n",
    "    \"learning_rate\": 5e-6,\n",
    "    \"lr_scheduler_type\": \"constant_with_warmup\",\n",
    "    \"warmup_steps\": 50,\n",
    "    \"max_steps\": training_max_steps, #1600, #2400, #32, #256, #3000,\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 800, #200,\n",
    "    \"eval_steps\": 400, #200,\n",
    "    \"logging_steps\": 25,\n",
    "\n",
    "    \"early_stopping_patience\": 10,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"wer\",\n",
    "    \"greater_is_better\": False,\n",
    "\n",
    "    # Early stopping implies checkpointing every evaluation, so limit the total checkpoints\n",
    "    # kept to avoid filling up disk:\n",
    "    \"save_total_limit\": 10,\n",
    "    \"seed\": 42,\n",
    "\n",
    "    \"predict_with_generate\": True,\n",
    "    \"generation_max_length\": 255,\n",
    "    # \"push_to_hub\": False,\n",
    "}\n",
    "\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": util.get_hf_metric_regex(\"epoch\")},\n",
    "    {\"Name\": \"learning_rate\", \"Regex\": util.get_hf_metric_regex(\"learning_rate\")},\n",
    "    {\"Name\": \"train:loss\", \"Regex\": util.get_hf_metric_regex(\"loss\")},\n",
    "    {\"Name\": \"validation:loss\", \"Regex\": util.get_hf_metric_regex(\"eval_loss\")},\n",
    "    {\n",
    "        \"Name\": \"validation:samples_per_sec\",\n",
    "        \"Regex\": util.get_hf_metric_regex(\"eval_samples_per_second\"),\n",
    "    },\n",
    "    {\"Name\": \"validation:wer\", \"Regex\": util.get_hf_metric_regex(\"eval_wer\")},\n",
    "    {\"Name\": \"validation:wer_ortho\", \"Regex\": util.get_hf_metric_regex(\"eval_wer_ortho\")},\n",
    "]\n",
    "\n",
    "estimator = HuggingFaceEstimator(\n",
    "    sagemaker_session=pipeline_session,\n",
    "    base_job_name=f\"whisper-fine-tune\",\n",
    "    entry_point=\"entry_train.py\",\n",
    "    source_dir=\"src\",\n",
    "    output_path=f\"s3://{bucket}/{pipeline_name}-trainjobs\",\n",
    "    role=role,\n",
    "    py_version=\"py310\",\n",
    "    pytorch_version=\"2.0\",\n",
    "    transformers_version=\"4.28\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\", # E.g. \"ml.g5.2xlarge\", \"ml.p3.2xlarge\"; # `training_instance_type` parameter does not work here, causing conflict with attribute in HuggingFace class. \n",
    "    # volume_size=30,\n",
    "    #keep_alive_period_in_seconds=900,  # Enable warm pools for faster debugging (you need quota)\n",
    "\n",
    "    environment={\n",
    "        # \"PIP_CACHE_DIR\": \"/opt/ml/sagemaker/warmpoolcache/pip\",  # For warm pools\n",
    "        # \"TOKENIZERS_PARALLELISM\": \"false\",\n",
    "    },\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    #distribution = distribution,\n",
    ")\n",
    "\n",
    "train_args = estimator.fit(\n",
    "    inputs={\n",
    "        \"dataset\": step_fetch.properties.ProcessingOutputConfig.Outputs[\"output\"].S3Output.S3Uri,\n",
    "    },\n",
    ")\n",
    "\n",
    "step_train_model = TrainingStep(\n",
    "    name=\"fine_tune_whisper\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822b4b3-160a-485c-b9b6-09a4dabb8cbf",
   "metadata": {},
   "source": [
    "## Evaluation Step: Evaluate the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5595899-2d8c-45c1-9e3a-fab0f24ef9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ProcessingStep is used to evaluate the performance of the trained model.\n",
    "# Based on the results of the evaluation, the model is created and deployed.\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "eval_processor = HuggingFaceProcessor(\n",
    "    sagemaker_session=pipeline_session,\n",
    "    base_job_name=f\"whisper-evaluation\",\n",
    "    role=role, \n",
    "    image_uri=image_uri,\n",
    "    instance_count=1,\n",
    "    instance_type=evaluation_instance_type,\n",
    "    py_version=\"py310\",\n",
    "    pytorch_version=\"2.0\", \n",
    "    transformers_version=\"4.28\", \n",
    "    volume_size_in_gb=40,\n",
    ")\n",
    "\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation_report\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "\n",
    "eval_args = eval_processor.run(\n",
    "    code=\"entry_evaluation.py\",\n",
    "    source_dir=\"src\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_fetch.properties.ProcessingOutputConfig.Outputs[\"output\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/output\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            # destination=f\"s3://{bucket}/{s3_prefix}/evaluation_report\",\n",
    "        ),\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--language_name\", language_name,\n",
    "    ],\n",
    ")\n",
    "\n",
    "step_evaluate_model = ProcessingStep(\n",
    "    name=\"evaluate_ft_whisper_model\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee2ef1-4a33-4e09-864d-375335f2df7b",
   "metadata": {},
   "source": [
    "## Model Step: Create Model to be registered to Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5cf0d6-5b8b-4bd8-aec3-406a9dd3359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "\n",
    "ft_whisper_model = HuggingFaceModel(\n",
    "    sagemaker_session=pipeline_session,\n",
    "    env={\n",
    "        \"HF_TASK\": \"automatic-speech-recognition\",\n",
    "    },\n",
    "    model_data=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    role=role,\n",
    "    py_version=\"py310\",\n",
    "    pytorch_version=\"2.0\",\n",
    "    transformers_version=\"4.28\",\n",
    ")\n",
    "\n",
    "s3_eval_path = step_evaluate_model.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "evaluation_s3_uri = f\"{s3_eval_path}/evaluation.json\"\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=evaluation_s3_uri,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_model_step_args = ft_whisper_model.register(\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.g4dn.xlarge\"],\n",
    "    model_package_group_name=model_package_name, \n",
    "    model_metrics=model_metrics,\n",
    "    approval_status=\"Approved\"\n",
    ")\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"register_ft_whisper_model\",\n",
    "    step_args=register_model_step_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb8fbf-af36-45af-bed4-77f9ced12ec5",
   "metadata": {},
   "source": [
    "## Condition Step: Check WER and conditionally register the packaged model to model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9873bed4-c696-4632-bf5b-01b65e3fd7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_evaluate_model.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.wer.value\",\n",
    "    ),\n",
    "    right=wer_threshold,\n",
    ")\n",
    "\n",
    "step_condition = ConditionStep(\n",
    "    name=\"check_whisper_evaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35963f71-2f98-4f1e-a15e-5818ef1e13dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Putting all steps together in one SageMaker Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78668c-d219-48dd-8e95-70c81b452f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# Create a Sagemaker Pipeline.\n",
    "# Each parameter for the pipeline must be set as a parameter explicitly when the pipeline is created.\n",
    "# Also pass in each of the steps created above.\n",
    "# Note that the order of execution is determined from each step's dependencies on other steps,\n",
    "# not on the order they are passed in below.\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        language_code,\n",
    "        language_name,\n",
    "        hf_secret,\n",
    "        fetching_instance_type,\n",
    "        training_max_steps,\n",
    "        evaluation_instance_type,\n",
    "        model_package_name,\n",
    "        wer_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        step_fetch, \n",
    "        step_train_model,\n",
    "        step_evaluate_model, \n",
    "        step_condition,\n",
    "    ],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b72b52-8c88-4f5c-a1a6-b132bb4e1ce9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ad087-2fdd-4caf-be36-5ae697c66096",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ba1d24-0c82-4090-abc9-d7ce2f0838c8",
   "metadata": {},
   "source": [
    "## Running the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6330f-7c40-460f-8c0f-4a2902368879",
   "metadata": {},
   "source": [
    "After we create the pipeline, we can start a pipeline execution with different pipeline parameters such as on `id` or `vi` language.\n",
    "\n",
    "Note: \n",
    "  - `TrainingMaxSteps=800` on Indonesian dataset takes about ~1.5 hours on the training step.\n",
    "  - `TrainingMaxSteps=32` on Vietnamese takes about ~16 minutes on the training step.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63e74f-c659-43c9-8df1-f402fbcde35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_time_str = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "execution = pipeline.start(\n",
    "    execution_display_name=f\"fine-tune-id-{date_time_str}\",\n",
    "    execution_description=\"fine-tune on id language\",\n",
    "    parameters=dict(\n",
    "        LanguageCode=\"id\",\n",
    "        LanguageName=LANGUAGE_NAMES[\"id\"],\n",
    "        HFSecretName=HFHUB_SECRET,\n",
    "        FetchingInstanceType=\"ml.m5.xlarge\",\n",
    "        #TrainingInstanceType=\"ml.g5.2xlarge\",\n",
    "        TrainingMaxSteps=800, #32, #800, #1600, #32, # Use 1600 to fine-tune id language for ~10 epochs\n",
    "        EvaluationInstanceType=\"ml.g4dn.xlarge\",\n",
    "        ModelPackageName=\"whisper-fine-tuned-id\",\n",
    "        WERThreshold=\"30\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05748900-4199-4a37-903c-39bad2cb2239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example pipeline execution on Vietnamese language\n",
    "\n",
    "date_time_str = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "execution = pipeline.start(\n",
    "    execution_display_name=f\"fine-tune-vi-{date_time_str}\",\n",
    "    execution_description=\"fine-tune on vi language\",\n",
    "    parameters=dict(\n",
    "        LanguageCode=\"vi\",\n",
    "        LanguageName=LANGUAGE_NAMES[\"vi\"],\n",
    "        HFSecretName=HFHUB_SECRET,\n",
    "        FetchingInstanceType=\"ml.m5.xlarge\",\n",
    "        #TrainingInstanceType=\"ml.g5.2xlarge\",\n",
    "        TrainingMaxSteps=32,\n",
    "        EvaluationInstanceType=\"ml.g4dn.xlarge\",\n",
    "        ModelPackageName=\"whisper-fine-tuned-vi\",\n",
    "        WERThreshold=\"30\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a7690-1709-4f20-b851-bb4251a25ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54234085-f1db-4381-8760-43ed33061f11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [Not working yet, ignore this section] Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcfb49-424f-48f7-aa03-76e064b51c7f",
   "metadata": {},
   "source": [
    "After we have fine-tuned models in Model Registry, we can deploy the model as a SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62361a-b0dc-4ae3-a258-65cf7454960d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "def get_approved_package(model_package_group_name):\n",
    "    \"\"\"Gets the latest approved model package for a model package group.\n",
    "\n",
    "    Args:\n",
    "        model_package_group_name: The model package group name.\n",
    "\n",
    "    Returns:\n",
    "        The SageMaker Model Package ARN.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the latest approved model package\n",
    "        response = sm.list_model_packages(\n",
    "            ModelPackageGroupName=model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            MaxResults=100,\n",
    "        )\n",
    "        approved_packages = response[\"ModelPackageSummaryList\"]\n",
    "\n",
    "        # Fetch more packages if none returned with continuation token\n",
    "        while len(approved_packages) == 0 and \"NextToken\" in response:\n",
    "            response = sm.list_model_packages(\n",
    "                ModelPackageGroupName=model_package_group_name,\n",
    "                ModelApprovalStatus=\"Approved\",\n",
    "                SortBy=\"CreationTime\",\n",
    "                MaxResults=100,\n",
    "                NextToken=response[\"NextToken\"],\n",
    "            )\n",
    "            approved_packages.extend(response[\"ModelPackageSummaryList\"])\n",
    "\n",
    "        # Return error if no packages found\n",
    "        if len(approved_packages) == 0:\n",
    "            error_message = (\n",
    "                f\"No approved ModelPackage found for ModelPackageGroup: {model_package_group_name}\"\n",
    "            )\n",
    "            raise Exception(error_message)\n",
    "\n",
    "        print(approved_packages)\n",
    "        # Return the pmodel package arn\n",
    "        model_package_arn = approved_packages[0][\"ModelPackageArn\"]\n",
    "        return approved_packages[0]\n",
    "        # return model_package_arn\n",
    "    except ClientError as e:\n",
    "        error_message = e.response[\"Error\"][\"Message\"]\n",
    "        raise Exception(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3eec67-fbea-4827-b757-e440ce0cfde4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pck = get_approved_package(\n",
    "    \"whisper-fine-tuned-id\"\n",
    "    #model_package_group_prefix + \"id\" #model_package_group_name\n",
    ")  \n",
    "model_description = sm.describe_model_package(ModelPackageName=pck[\"ModelPackageArn\"])\n",
    "\n",
    "model_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655e0a8-76e4-4e7e-adfa-6bbc80f37fda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "from sagemaker.serializers import DataSerializer\n",
    "\n",
    "date_time_str = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "audio_serializer = DataSerializer(content_type='audio/x-audio') # using x-audio to support multiple audio formats\n",
    "\n",
    "model = ModelPackage(\n",
    "    role=role, \n",
    "    model_package_arn=model_description[\"ModelPackageArn\"], \n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "endpoint_name = \"ft-whisper-model-id-\" + date_time_str\n",
    "print(f\"EndpointName={endpoint_name}\")\n",
    "model.deploy(initial_instance_count=1, \n",
    "             instance_type=\"ml.g4dn.xlarge\", \n",
    "             serializer=audio_serializer, # serializer for our audio data\n",
    "             endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae71f3-6f71-43ea-98ea-5b4bd22af6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "sample_test_audio = 'sample_data/common_voice_id_26208380.mp3'\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c6b525-0908-4ba5-b57d-1ef6b4d60aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b57c2-7cfe-4501-aeef-7e5d71380773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = predictor.predict(data=sample_test_audio)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e947557-6150-4242-bbc7-f69d17a8ad26",
   "metadata": {},
   "source": [
    "## Cleanup (removing unused resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2875d-d262-4b3f-86ea-c552cbfd6e06",
   "metadata": {},
   "source": [
    "If you no longer use the packages in model registry, endpoints, and pipeline after you finish with this notebook, you can delete them to avoid any unintended charges.\n",
    "Here are the example codes for clean up, you can adjust the code to follow your variable names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069fc00-e574-43a1-a079-3e63401f777f",
   "metadata": {},
   "source": [
    "### Delete Model Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7d5e6-35f8-4f0f-9e51-b67cfd11a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker\")\n",
    "\n",
    "for d in sm.list_model_packages(ModelPackageGroupName=model_package_group_name)[\n",
    "    \"ModelPackageSummaryList\"\n",
    "]:\n",
    "    print(d[\"ModelPackageArn\"])\n",
    "    sm.delete_model_package(ModelPackageName=d[\"ModelPackageArn\"])\n",
    "\n",
    "sm.delete_model_package_group(ModelPackageGroupName=model_package_group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738927f0-7f7b-4445-a459-a0d0b1f51a4c",
   "metadata": {},
   "source": [
    "### Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e744d6-f861-4bb7-8c24-533d1e1fb99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2f883-127e-4005-b130-0e60dea8b8e9",
   "metadata": {},
   "source": [
    "### Delete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49450a34-8dd5-4f46-a23b-53fc6f09833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.delete()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
